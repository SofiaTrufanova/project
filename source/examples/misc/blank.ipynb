{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8228e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
      "Collecting pingouin\n",
      "  Downloading pingouin-0.5.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from pingouin) (3.10.0)\n",
      "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.12/dist-packages (from pingouin) (2.2.2)\n",
      "Collecting pandas-flavor (from pingouin)\n",
      "  Downloading pandas_flavor-0.8.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pingouin) (1.16.3)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from pingouin) (0.13.2)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from pingouin) (0.14.5)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from pingouin) (0.9.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5->pingouin) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5->pingouin) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5->pingouin) (2025.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (3.2.5)\n",
      "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (from pandas-flavor->pingouin) (2025.11.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->pingouin) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5->pingouin) (1.17.0)\n",
      "Downloading pingouin-0.5.5-py3-none-any.whl (204 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m204.4/204.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas_flavor-0.8.1-py3-none-any.whl (8.5 kB)\n",
      "Installing collected packages: pandas-flavor, pingouin\n",
      "Successfully installed pandas-flavor-0.8.1 pingouin-0.5.5\n"
     ]
    }
   ],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
    "%pip install torch torchvision pingouin scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1566daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/VanessB/pytorch-fd.git\n",
      "  Cloning https://github.com/VanessB/pytorch-fd.git to /tmp/pip-req-build-fpowush5\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/VanessB/pytorch-fd.git /tmp/pip-req-build-fpowush5\n",
      "  Resolved https://github.com/VanessB/pytorch-fd.git to commit 477ec5229231acfa632d08dbb953c30716b182bd\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from torchfd==2025.8.1) (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->torchfd==2025.8.1) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.1->torchfd==2025.8.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.1->torchfd==2025.8.1) (3.0.3)\n",
      "Building wheels for collected packages: torchfd\n",
      "  Building wheel for torchfd (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torchfd: filename=torchfd-2025.8.1-py3-none-any.whl size=33144 sha256=be2b065704202347239817dd97b95a73c8eec3a6401600a69a2d61e8e400e0d1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8xuh7pju/wheels/3d/d1/cb/a4c920016f2d6d02bd5888ac420ea64767dd8e5da4d1ae689b\n",
      "Successfully built torchfd\n",
      "Installing collected packages: torchfd\n",
      "Successfully installed torchfd-2025.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/VanessB/pytorch-fd.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beefa054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8234a1f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'architectures'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-610547021.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0marchitectures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_architecture_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dEmbedder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDenseClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_infomax_embedder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'architectures'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "from architectures import get_architecture_factory\n",
    "from modules import Conv2dEmbedder, DenseClassifier\n",
    "from training import train_infomax_embedder, convert_to_embeddings, classification_callback\n",
    "from plots import plot_history, plot_embeddings\n",
    "from statistics import MultivariateNormalTests\n",
    "import infomax.channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d82f0c03",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchfd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-333971626.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchfd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchfd'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torchfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a867b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 426k/170M [00:00<04:52, 582kB/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-717992948.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# –î–∞—Ç–∞—Å–µ—Ç—ã\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgz_md5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# download the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"https\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ CIFAR-10\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# –î–∞—Ç–∞—Å–µ—Ç—ã\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoader'—ã\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "print(f\"–†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(train_dataset)}\")\n",
    "print(f\"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ë–ê–ó–û–í–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø (–æ–¥–∏–Ω–∞–∫–æ–≤–∞—è –¥–ª—è –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)\n",
    "base_config = {\n",
    "    \"embedding_dim\": 128,\n",
    "    \"batch_size_train\": 512,\n",
    "    \"n_epochs\": 100,  # –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å –¥–ª—è —Ç–µ—Å—Ç–∞\n",
    "    \"input_p\": 0.2,\n",
    "    \"output_p\": 0.1,\n",
    "    \"marginalizer\": \"OuterProductMarginalizer\",\n",
    "    \"distribution\": \"normal\",\n",
    "    \"discriminator_network_inner_dim\": 256,\n",
    "    \"discriminator_network_output_dim\": 64\n",
    "}\n",
    "\n",
    "# –ê–†–•–ò–¢–ï–ö–¢–£–†–´ –î–õ–Ø –°–†–ê–í–ù–ï–ù–ò–Ø\n",
    "architectures_to_test = [\n",
    "    \"DotProduct\",           # ultra-simple\n",
    "    \"Bilinear\",             # simple  \n",
    "    \"AdditiveGaussainT\",    # theoretical\n",
    "    \"SeparableT\",           # medium\n",
    "    \"DenseT\",               # complex\n",
    "    \"VeryDenseT\"            # ultra-complex\n",
    "]\n",
    "\n",
    "print(\"–ë—É–¥–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:\", architectures_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_experiment(architecture_name, config, train_loader, test_loader, device):\n",
    "    \"\"\"\n",
    "    –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–∏–Ω –ø–æ–ª–Ω—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å –∑–∞–¥–∞–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üöÄ –ó–ê–ü–£–°–ö–ê–ï–ú –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢: {architecture_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 1. –°–û–ó–î–ê–Å–ú –ú–û–î–ï–õ–¨\n",
    "    backbone = Conv2dEmbedder(embedding_dim=config[\"embedding_dim\"])\n",
    "    normalization = torch.nn.BatchNorm1d(config[\"embedding_dim\"], affine=False)\n",
    "    embedder_network = torch.nn.Sequential(backbone, normalization)\n",
    "    \n",
    "    # 2. –ü–û–õ–£–ß–ê–ï–ú –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† –°–†–ê–í–ù–ï–ù–ò–Ø\n",
    "    factory = get_architecture_factory(config[\"embedding_dim\"], config)\n",
    "    discriminator_network = factory[architecture_name]()\n",
    "    \n",
    "    # 3. –°–û–ë–ò–†–ê–ï–ú –ü–û–õ–ù–£–Æ –ú–û–î–ï–õ–¨\n",
    "    model = infomax.embeddings.Embedder(\n",
    "        embedder_network,\n",
    "        discriminator_network,\n",
    "        infomax.channels.BoundedVarianceGaussianChannel(config[\"input_p\"]),\n",
    "        infomax.channels.BoundedVarianceGaussianChannel(config[\"output_p\"]),\n",
    "    ).to(device)\n",
    "    \n",
    "    # 4. –ó–ê–ü–£–°–ö–ê–ï–ú –û–ë–£–ß–ï–ù–ò–ï\n",
    "    history = train_infomax_embedder(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        device,\n",
    "        n_epochs=config[\"n_epochs\"],\n",
    "        callback=classification_callback,\n",
    "        distribution=config[\"distribution\"]\n",
    "    )\n",
    "    \n",
    "    # 5. –°–û–•–†–ê–ù–Ø–ï–ú –†–ï–ó–£–õ–¨–¢–ê–¢–´\n",
    "    results = {\n",
    "        'architecture': architecture_name,\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'final_embeddings': convert_to_embeddings(model.embedder_network, test_loader, device)\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ {architecture_name} –∑–∞–≤–µ—Ä—à—ë–Ω!\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–ê–ü–£–°–ö–ê–ï–ú –í–°–ï –ê–†–•–ò–¢–ï–ö–¢–£–†–´\n",
    "all_results = {}\n",
    "\n",
    "for arch_name in architectures_to_test:\n",
    "    try:\n",
    "        results = run_single_experiment(arch_name, base_config, train_loader, test_loader, device)\n",
    "        all_results[arch_name] = results\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ —Å {arch_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nüéØ –£—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤: {len(all_results)}/{len(architectures_to_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–û–ó–î–ê–Å–ú –°–í–û–î–ù–£–Æ –¢–ê–ë–õ–ò–¶–£ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\n",
    "summary_data = []\n",
    "\n",
    "for arch_name, results in all_results.items():\n",
    "    history = results['history']\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    try:\n",
    "        # Accuracy (–±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)\n",
    "        if 'classification_logistic_regression' in history and 'accuracy' in history['classification_logistic_regression']:\n",
    "            accuracy_data = history['classification_logistic_regression']['accuracy']\n",
    "            final_accuracy = accuracy_data[-1][2] if accuracy_data else 0.0\n",
    "        else:\n",
    "            final_accuracy = 0.0\n",
    "        \n",
    "        # Normalcy test (–±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)\n",
    "        if 'distribution' in history and 'henze_zirkler_(test)' in history['distribution']:\n",
    "            normalcy_data = history['distribution']['henze_zirkler_(test)']\n",
    "            final_normalcy = normalcy_data[-1][2] if normalcy_data else 0.0\n",
    "        else:\n",
    "            final_normalcy = 0.0\n",
    "        \n",
    "        # Loss (–±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)\n",
    "        if 'training' in history and 'loss' in history['training']:\n",
    "            loss_data = history['training']['loss']\n",
    "            final_loss = loss_data[-1][2] if loss_data else 0.0\n",
    "        else:\n",
    "            final_loss = 0.0\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Architecture': arch_name,\n",
    "            'Accuracy': final_accuracy,\n",
    "            'Normalcy_p-value': final_normalcy,\n",
    "            'Final_Loss': final_loss\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {arch_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# –°–û–ó–î–ê–Å–ú –ò –í–´–í–û–î–ò–ú –¢–ê–ë–õ–ò–¶–£\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"üìä –°–í–û–î–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:\")\n",
    "print(\"=\"*60)\n",
    "print(summary_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ì–†–ê–§–ò–ö–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê –ì–ò–ü–û–¢–ï–ó–´\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Accuracy vs Architecture\n",
    "axes[0,0].bar(summary_df['Architecture'], summary_df['Accuracy'], color='skyblue', alpha=0.7)\n",
    "axes[0,0].set_title('Accuracy –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º')\n",
    "axes[0,0].set_ylabel('Accuracy')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Normalcy vs Architecture\n",
    "axes[0,1].bar(summary_df['Architecture'], summary_df['Normalcy_p-value'], color='lightcoral', alpha=0.7)\n",
    "axes[0,1].set_title('–ù–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º')\n",
    "axes[0,1].set_ylabel('p-value –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. –ö–û–†–†–ï–õ–Ø–¶–ò–Ø: Accuracy vs Normalcy\n",
    "axes[1,0].scatter(summary_df['Normalcy_p-value'], summary_df['Accuracy'], s=100, alpha=0.7)\n",
    "for i, row in summary_df.iterrows():\n",
    "    axes[1,0].annotate(row['Architecture'], \n",
    "                      (row['Normalcy_p-value'], row['Accuracy']),\n",
    "                      xytext=(5, 5), textcoords='offset points')\n",
    "axes[1,0].set_xlabel('p-value –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏')\n",
    "axes[1,0].set_ylabel('Accuracy')\n",
    "axes[1,0].set_title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è: –ù–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å ‚Üî Accuracy')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Loss –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º\n",
    "axes[1,1].bar(summary_df['Architecture'], summary_df['Final_Loss'], color='lightgreen', alpha=0.7)\n",
    "axes[1,1].set_title('Final Loss –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º')\n",
    "axes[1,1].set_ylabel('Loss')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–†–ê–í–ù–ï–ù–ò–ï –ü–†–û–°–¢–†–ê–ù–°–¢–í–ê –≠–ú–ë–ï–î–î–ò–ù–ì–û–í –î–õ–Ø –õ–£–ß–®–ï–ô –ò –•–£–î–®–ï–ô –ê–†–•–ò–¢–ï–ö–¢–£–†–´\n",
    "best_arch = summary_df.iloc[0]['Architecture']\n",
    "worst_arch = summary_df.iloc[-1]['Architecture']\n",
    "\n",
    "print(f\"üéØ –õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {best_arch}\")\n",
    "print(f\"üìâ –•—É–¥—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {worst_arch}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "best_embeddings, best_labels = all_results[best_arch]['final_embeddings']\n",
    "best_embeddings = best_embeddings.detach().cpu().numpy()\n",
    "best_labels = best_labels.detach().cpu().numpy()\n",
    "\n",
    "# –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ö—É–¥—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã  \n",
    "worst_embeddings, worst_labels = all_results[worst_arch]['final_embeddings']\n",
    "worst_embeddings = worst_embeddings.detach().cpu().numpy()\n",
    "worst_labels = worst_labels.detach().cpu().numpy()\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "classes = np.unique(best_labels)\n",
    "for label in classes:\n",
    "    # –õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
    "    selected = best_embeddings[best_labels==label]\n",
    "    axes[0].scatter(selected[:,0], selected[:,1], label=f'Class {label}', alpha=0.6, s=30)\n",
    "    \n",
    "    # –•—É–¥—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
    "    selected = worst_embeddings[worst_labels==label] \n",
    "    axes[1].scatter(selected[:,0], selected[:,1], label=f'Class {label}', alpha=0.6, s=30)\n",
    "\n",
    "axes[0].set_title(f'–≠–º–±–µ–¥–¥–∏–Ω–≥–∏: {best_arch} (Accuracy: {summary_df.iloc[0][\"Accuracy\"]:.3f})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_title(f'–≠–º–±–µ–¥–¥–∏–Ω–≥–∏: {worst_arch} (Accuracy: {summary_df.iloc[-1][\"Accuracy\"]:.3f})')  \n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ee7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\n",
    "print(\"üìà –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å—é –∏ accuracy\n",
    "correlation = np.corrcoef(summary_df['Normalcy_p-value'], summary_df['Accuracy'])[0,1]\n",
    "print(f\"üìä –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å—é –∏ accuracy: {correlation:.3f}\")\n",
    "\n",
    "# –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É\n",
    "optimal_idx = summary_df['Accuracy'].idxmax()\n",
    "optimal_arch = summary_df.loc[optimal_idx, 'Architecture']\n",
    "optimal_accuracy = summary_df.loc[optimal_idx, 'Accuracy']\n",
    "optimal_normalcy = summary_df.loc[optimal_idx, 'Normalcy_p-value']\n",
    "\n",
    "print(f\"\\nüéØ –û–ü–¢–ò–ú–ê–õ–¨–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê: {optimal_arch}\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {optimal_accuracy:.3f}\")\n",
    "print(f\"   ‚Ä¢ p-value –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏: {optimal_normalcy:.3f}\")\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑ —Å–ø–µ–∫—Ç—Ä–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏\n",
    "simple_archs = ['DotProduct', 'Bilinear', 'AdditiveGaussainT']\n",
    "complex_archs = ['DenseT', 'VeryDenseT']\n",
    "medium_archs = ['SeparableT']\n",
    "\n",
    "simple_avg = summary_df[summary_df['Architecture'].isin(simple_archs)]['Accuracy'].mean()\n",
    "medium_avg = summary_df[summary_df['Architecture'].isin(medium_archs)]['Accuracy'].mean()  \n",
    "complex_avg = summary_df[summary_df['Architecture'].isin(complex_archs)]['Accuracy'].mean()\n",
    "\n",
    "print(f\"\\nüìà –°–†–ï–î–ù–Ø–Ø ACCURACY –ü–û –ì–†–£–ü–ü–ê–ú –°–õ–û–ñ–ù–û–°–¢–ò:\")\n",
    "print(f\"   ‚Ä¢ –ü—Ä–æ—Å—Ç—ã–µ: {simple_avg:.3f}\")\n",
    "print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–µ: {medium_avg:.3f}\")\n",
    "print(f\"   ‚Ä¢ –°–ª–æ–∂–Ω—ã–µ: {complex_avg:.3f}\")\n",
    "\n",
    "# –í–´–í–û–î–´\n",
    "print(f\"\\nüé™ –í–´–í–û–î–´:\")\n",
    "print(\"=\"*30)\n",
    "if correlation > 0.5:\n",
    "    print(\"‚úÖ –ì–∏–ø–æ—Ç–µ–∑–∞ –ü–û–î–¢–í–ï–†–ñ–î–ï–ù–ê: –í—ã—Å–æ–∫–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å—é –∏ accuracy\")\n",
    "else:\n",
    "    print(\"‚ùå –ì–∏–ø–æ—Ç–µ–∑–∞ –ù–ï –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞: –ù–∏–∑–∫–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å—é –∏ accuracy\")\n",
    "\n",
    "if medium_avg > simple_avg and medium_avg > complex_avg:\n",
    "    print(\"‚úÖ –ù–∞–π–¥–µ–Ω–∞ '–∑–æ–ª–æ—Ç–∞—è —Å–µ—Ä–µ–¥–∏–Ω–∞' —Å–ª–æ–∂–Ω–æ—Å—Ç–∏!\")\n",
    "elif simple_avg > complex_avg:\n",
    "    print(\"‚ö†Ô∏è  –ü—Ä–æ—Å—Ç—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Ä–∞–±–æ—Ç–∞—é—Ç –ª—É—á—à–µ —Å–ª–æ–∂–Ω—ã—Ö\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  –°–ª–æ–∂–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Ä–∞–±–æ—Ç–∞—é—Ç –ª—É—á—à–µ –ø—Ä–æ—Å—Ç—ã—Ö\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –î–õ–Ø –û–¢–ß–Å–¢–ê\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "results_dir = f\"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "import os\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É\n",
    "summary_df.to_csv(f'{results_dir}/summary.csv', index=False)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é\n",
    "with open(f'{results_dir}/config.json', 'w') as f:\n",
    "    json.dump(base_config, f, indent=2)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫–∏\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(summary_df['Architecture'], summary_df['Accuracy'])\n",
    "plt.title('Accuracy –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{results_dir}/accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(f\"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É: {results_dir}\")\n",
    "print(\"üìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ:\")\n",
    "print(\"   - summary.csv - —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\")\n",
    "print(\"   - config.json - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\") \n",
    "print(\"   - accuracy_comparison.png - –≥—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
